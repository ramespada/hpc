<h1 id="cuda">CUDA</h1>

<blockquote>
  <p>CUDA es un modelo escalable para programación paralela que habilita el uso de GPU para la programación de proposito general.
Cuda es una plateaforma y un modelo de programación para GPUs. La plateaforma permite utilizar GPUs para computación de proposito general. Cuda provee extensiones para  C/C++ y Fortran.</p>
</blockquote>

<p>En CUDA, tanto CPUs como GPUs son utilizados. En programación <em>heterogenea</em> tipicamente nombramos <em>host</em> y <em>device</em> para referirnos a la CPU y GPU respectivamente. Tanto CPU como GPUs son plataformas separadas con su propio espacio de memoria.</p>

<p>Generalmente corremos serialmente en la CPU y descargamos el calculo paralelo a las GPUs.</p>

<p>En el siguiente bloque de código se puede diferenciar un programa en C de uno de CUDA.</p>
<div style="float:left;right-margin:30px;">

  <p><strong>C</strong></p>

  <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">c_hello</span><span class="p">(){</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"Hello World!</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">c_hello</span><span class="p">();</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>  </div>

</div>
<div>

  <p><strong>CUDA</strong></p>

  <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">cuda_hello</span><span class="p">(){</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"Hello World from GPU!</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">cuda_hello</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span> 
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>  </div>

</div>

<p>La principal diferencia entre C y CUDa es el especificador <code class="language-plaintext highlighter-rouge">__global__</code> y la sintaxis de <code class="language-plaintext highlighter-rouge">&lt;&lt;&lt;...&gt;&gt;&gt;</code> .</p>

<p>El <code class="language-plaintext highlighter-rouge">__global__</code> indica una función que corre en el <em>device</em> (GPU). Estas funciones pueden ser llamadas desde el código del <em>host</em>, e.g. el <code class="language-plaintext highlighter-rouge">main()</code> para este ejemplo, y son tambien conocidas como “<em>kernels</em>”.</p>

<p>Cuando un kernel es llamado, la conficuración de ejecucion es proveida mediante <code class="language-plaintext highlighter-rouge">&lt;&lt;&lt;...&gt;&gt;&gt;</code>, e.g. <code class="language-plaintext highlighter-rouge">cuda_hello&lt;&lt;&lt;1,1&gt;&gt;&gt;()</code>. Ln la terminología de CUDA esto es llamado  “<em>kernel launch</em>”. Luego veremos que significa el parámetros <code class="language-plaintext highlighter-rouge">(1,1)</code>.</p>

<h2 id="compilando-programas-con-cuda">Compilando programas con CUDA.</h2>

<p>El compilador de CUDa es similar al de C. NVIDIA prevee a CUDa un compilador llamado <code class="language-plaintext highlighter-rouge">nvcc</code>, tipicamente guardado en un archivo con extensión <code class="language-plaintext highlighter-rouge">.cu</code>. FPor ejemplo:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$&gt;</span> nvcc hello.cu <span class="nt">-o</span> hello
</code></pre></div></div>

<p>Podría ser que encuentres el siguiente warning a compilar el programa:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
</code></pre></div></div>

<p>Este warning pued ser ignorado por el momento.</p>

<h2 id="putting-things-in-actions">Putting things in actions.</h2>

<p>El <em>hello world</em> en CUDa no hace nada, incluso si es compilado nada se mostraría en la pantalla. Para poner en práctica vamos a realizar adicón de vectores:</p>

<p>El siguiente es un ejemplo de adición implementado en C (<a href="./CUDA/vector_add.c"><code class="language-plaintext highlighter-rouge">./vector_add.c</code></a>). El ejemplo computa la suma de dos vectores guardados en el array <code class="language-plaintext highlighter-rouge">a</code> y <code class="language-plaintext highlighter-rouge">b</code> y los guarda en el array <code class="language-plaintext highlighter-rouge">out</code>.</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#define N 10000000
</span>
<span class="kt">void</span> <span class="nf">vector_add</span><span class="p">(</span><span class="kt">float</span> <span class="o">*</span><span class="n">out</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="kt">int</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">){</span>
        <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(){</span>
    <span class="kt">float</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="o">*</span><span class="n">out</span><span class="p">;</span> 

    <span class="c1">// Allocate memory</span>
    <span class="n">a</span>   <span class="o">=</span> <span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)</span> <span class="o">*</span> <span class="n">N</span><span class="p">);</span>
    <span class="n">b</span>   <span class="o">=</span> <span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)</span> <span class="o">*</span> <span class="n">N</span><span class="p">);</span>
    <span class="n">out</span> <span class="o">=</span> <span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)</span> <span class="o">*</span> <span class="n">N</span><span class="p">);</span>

    <span class="c1">// Initialize array</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">){</span>
        <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="p">;</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="c1">// Main function</span>
    <span class="n">vector_add</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">N</span><span class="p">);</span>
<span class="p">}</span>

</code></pre></div></div>

<h2 id="ejercicio-converting-vector-addition-to-cuda">Ejercicio: Converting vector addition to CUDA</h2>

<p>In the first exercise, we will convert <code class="language-plaintext highlighter-rouge">vector_add.c</code> to CUDA program <code class="language-plaintext highlighter-rouge">vector_add.cu</code> by using the hello world as example.</p>

<ol>
  <li>Copiar <code class="language-plaintext highlighter-rouge">vector_add.c</code> to <code class="language-plaintext highlighter-rouge">vector_add.cu</code></li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$&gt;</span> <span class="nb">cp </span>vector_add.c vector_add.cu
</code></pre></div></div>

<ol>
  <li>Convertir <code class="language-plaintext highlighter-rouge">vector_add()</code> a GPU kernel</li>
</ol>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">vector_add</span><span class="p">(</span><span class="kt">float</span> <span class="o">*</span><span class="n">out</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="kt">int</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">){</span>
        <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<ol>
  <li>Cambiar <code class="language-plaintext highlighter-rouge">vector_add()</code> llamado en <code class="language-plaintext highlighter-rouge">main()</code> a la llamada del kernel</li>
</ol>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vector_add</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">N</span><span class="p">);</span>
</code></pre></div></div>

<ol>
  <li>Compilar y correr el programa
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$&gt;</span> nvcc vector_add.c <span class="nt">-o</span> vector_add
<span class="nv">$&gt;</span> ./vector_add
</code></pre></div>    </div>
  </li>
</ol>

<p>Notarás que el programa no funciona correctamente. La rason es que CPU y GPUs son entidades separadas, ambas tienen su propia memoria. La CPU no puede acceder a la memoria de la GPU y vice versa. EN la terminologia de CUDA, la memoria de la CPU es llamada <em>host memory</em> y la de la GPU <em>device memory</em>. Los Poinnters a CPU y GPU son llamados <em>host pointer</em> y <em>device pointer</em> respectivamente.</p>

<p>Para que los datos sean accesibles por la GPU es necesario que sean presentados en la <em>device memory</em>.</p>

<p>A continuación se presenta el workflow común de programas CUDA:</p>

<ol>
  <li>Alocatar host memory e ininicializar host data</li>
  <li>Alocatar device memory</li>
  <li>Transferir input data desde el host a la device memory</li>
  <li>Ejecutar kernels</li>
  <li>Transferir output desde la device memory al host</li>
</ol>

<p>Hasta ahora solo hecmo hecho los pasos 1 y 4.</p>

<p>Vamos a agregar los pasos 2, 3, y 5 a nuestro programa para completar el ejercicio:</p>

<p>Para el manejo de memoria del device CUDA provee varias funciones para alocatar device memory. Las más comunes son <code class="language-plaintext highlighter-rouge">cudaMalloc()</code> y <code class="language-plaintext highlighter-rouge">cudaFree()</code>.</p>

<p>La sintaxis para estas funciones es:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cudaMalloc</span><span class="p">(</span><span class="kt">void</span> <span class="o">**</span><span class="n">devPtr</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">count</span><span class="p">);</span>
<span class="n">cudaFree</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">devPtr</span><span class="p">);</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">cudaMalloc()</code> allocatea memoria de tamaño <code class="language-plaintext highlighter-rouge">count</code> en la memoria del device y actualiza el device pointer <code class="language-plaintext highlighter-rouge">devPtr</code> a la memoria alocatada. <code class="language-plaintext highlighter-rouge">cudaFree()</code> desalocatea la region dememoria del device hacia donde el puntero del device <code class="language-plaintext highlighter-rouge">devPtr</code> apunta. Estas funciones son comparables con <code class="language-plaintext highlighter-rouge">malloc()</code> y <code class="language-plaintext highlighter-rouge">free()</code> de C, respectivamente.</p>

<p>Transferir datos entre hosy y device memory puede ser hecho atravez de la función <code class="language-plaintext highlighter-rouge">cudaMemcpy</code>, el cual es similar a <code class="language-plaintext highlighter-rouge">memcpy</code> de C. La sintaxis de <code class="language-plaintext highlighter-rouge">cudaMemcpy</code> es:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cudaMemcpy</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">dst</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">src</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">count</span><span class="p">,</span> <span class="n">cudaMemcpyKind</span><span class="err"> </span><span class="n">kind</span><span class="p">)</span>
</code></pre></div></div>

<p>La funcipn copia una memoria de tamaño <code class="language-plaintext highlighter-rouge">count</code> de <code class="language-plaintext highlighter-rouge">src</code> a <code class="language-plaintext highlighter-rouge">dst</code>. <code class="language-plaintext highlighter-rouge">kind</code> indica la dirección. En egeneral el valor de <code class="language-plaintext highlighter-rouge">kind</code> es <code class="language-plaintext highlighter-rouge">cudaMemcpyHostToDevice</code> ó <code class="language-plaintext highlighter-rouge">cudaMemcpyDeviceToHost</code>. Hay otros posibles valores pero no lo vamos a desarrollar en este tutorial.</p>

<p>Ahora debemos:</p>
<ul>
  <li>
    <p>Alocatar y desalocatar device memory para <code class="language-plaintext highlighter-rouge">a</code>, <code class="language-plaintext highlighter-rouge">b</code>, y <code class="language-plaintext highlighter-rouge">out</code>.</p>
  </li>
  <li>
    <p>Transferir <code class="language-plaintext highlighter-rouge">a</code>, <code class="language-plaintext highlighter-rouge">b</code>, y <code class="language-plaintext highlighter-rouge">out</code> entre host y device memory.</p>
    <ul>
      <li>Quiz: Que array debe ser transferido antes y despues de la ejecución del kernel?</li>
    </ul>
  </li>
</ul>

<p>Un ejemplo para el array ‘a’ seria:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">main</span><span class="p">(){</span>
    <span class="kt">float</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="o">*</span><span class="n">out</span><span class="p">;</span>
    <span class="kt">float</span> <span class="o">*</span><span class="n">d_a</span><span class="p">;</span>

    <span class="n">a</span> <span class="o">=</span> <span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)</span> <span class="o">*</span> <span class="n">N</span><span class="p">);</span>

    <span class="c1">// Allocate device memory for a</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_a</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)</span> <span class="o">*</span> <span class="n">N</span><span class="p">);</span>
    
    <span class="c1">// Transfer data from host to device memory</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_a</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)</span> <span class="o">*</span> <span class="n">N</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>

    <span class="err">…</span>
    <span class="n">vector_add</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">d_a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">N</span><span class="p">);</span>
    <span class="err">…</span>

    <span class="c1">// Cleanup after kernel execution</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_a</span><span class="p">);</span>
    <span class="n">free</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<ul>
  <li>Compilar y medir performance (Ver solucion en (<a href="./solutions/CUDA/vector_add.cu"><code class="language-plaintext highlighter-rouge">./solutions/vector_add.cu</code></a>) )</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$&gt;</span> nvcc vector_add.cu <span class="nt">-o</span> vector_add
<span class="nv">$&gt;</span> <span class="nb">time</span> ./vector_add
</code></pre></div></div>

<p>Para medir la performance, usar <code class="language-plaintext highlighter-rouge">time</code> no da mucha inromación. NVIDIA provee un comando llamado <code class="language-plaintext highlighter-rouge">nvprof</code>, el cua da más información.</p>

<p>Para evaluar nuestra suma de vectores se puede usar el siguiente comando:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$&gt;</span> nvprof ./vector_add
</code></pre></div></div>

<p>El resultado en Tesla M2050 dio:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>==6326== Profiling application: ./vector_add
==6326== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 97.55%  1.42529s         1  1.42529s  1.42529s  1.42529s  vector_add(float*, float*, float*, int)
  1.39%  20.318ms         2  10.159ms  10.126ms  10.192ms  [CUDA memcpy HtoD]
  1.06%  15.549ms         1  15.549ms  15.549ms  15.549ms  [CUDA memcpy DtoH]
</code></pre></div></div>

<p>Hasta ahora el programa no corre en paralelo ya que la la configuración de ejecución del kernel es <code class="language-plaintext highlighter-rouge">&lt;&lt;&lt;1,1&gt;&gt;&gt;</code>, esto indica que el kernel es enviado con solo 1 thread.</p>

<h2 id="camino-a-paralelizar">Camino a paralelizar</h2>

<p>CUDA usa la configuracion de ejecución del kernel <code class="language-plaintext highlighter-rouge">&lt;&lt;&lt;...&gt;&gt;&gt;</code> para avisar cuantos threads mandar a la GPU. CUDA organiza los threads en un grupo llamado “<strong><em>thread block</em></strong>”. El kernel puede mandar multiples thread blocks, oorganizados en una estructura de grilla ó “<strong><em>grid</em></strong>”.</p>

<p>La sintaxis sería:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;&lt;&lt; M , T &gt;&gt;&gt;
</code></pre></div></div>
<p>Lo que indicaría que el kernel manda una grilla de <code class="language-plaintext highlighter-rouge">M</code> thread blocks, cada trhread con <code class="language-plaintext highlighter-rouge">T</code> threads paralelos.</p>

<p>Si quisieramos paralelizar el codigo de suma de vectores usando 1 grupo de 256 threads la configuración sería:</p>
<pre><code class="language-C">vector_add &lt;&lt;&lt; 1 , 256 &gt;&gt;&gt; (d_out, d_a, d_b, N);
</code></pre>

<p>CUDA prevee variables prefabricadas para acceder a la información del thread. En nuestro caso usariemos:: <code class="language-plaintext highlighter-rouge">threadIdx.x</code> and <code class="language-plaintext highlighter-rouge">blockIdx.x</code>.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">threadIdx.x</code> contiene el indice del thread dentro del bloque</li>
  <li><code class="language-plaintext highlighter-rouge">blockDim.x</code> contiene el tamaño del bloque (el numero de threads en el thread block).</li>
</ul>

<p>Para la configuración de <code class="language-plaintext highlighter-rouge">vector_add()</code> el valor de <code class="language-plaintext highlighter-rouge">threadIdx.x</code> va de 0 a 255 y el de <code class="language-plaintext highlighter-rouge">blockDim.x</code> es 256.</p>

<p>Recalls the kernel of single thread version in <a href="./vector_add.cu"><code class="language-plaintext highlighter-rouge">vector_add.cu</code></a>. Notes that we modified the <code class="language-plaintext highlighter-rouge">vector_add()</code> kernel a bit to make the explanation easier.</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">vector_add</span><span class="p">(</span><span class="kt">float</span> <span class="o">*</span><span class="n">out</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="kt">int</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">index</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="n">i</span> <span class="o">+=</span> <span class="n">stride</span><span class="p">){</span>
        <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>En esta implementación solo un thread computa la adición iterando atravez del array entero. Con 256 threads la adición puede esparcirse atravez de los threads y computarse simultaneamente.</p>

<p>Para el thread <code class="language-plaintext highlighter-rouge">k</code>-ésimo, el loop empieza en el el <code class="language-plaintext highlighter-rouge">k</code>-éstimo elemento e itera mediante el array con un <code class="language-plaintext highlighter-rouge">stride</code> de 256. Por ejemplo, en el 0-éstima iteración el <code class="language-plaintext highlighter-rouge">k</code>-estimo thread computa la adición del <code class="language-plaintext highlighter-rouge">k</code>-esimo elemento. En la siguiente iteración la <code class="language-plaintext highlighter-rouge">k</code>-ésima computa la adición de <code class="language-plaintext highlighter-rouge">(k+256)</code>-iestimo elemento y así.</p>

<p>La siguiente imagen muestra una ilustración de la idea:</p>

<p><img src="./CUDA/01_parallel_thread.png" alt="parallel thread" title="parallel thread" /></p>

<p><strong>Ejercicio: Intenta implementar esto en <code class="language-plaintext highlighter-rouge">vector_add_thread.cu</code></strong></p>

<ol>
  <li>Copiar <code class="language-plaintext highlighter-rouge">vector_add.cu</code> ao <code class="language-plaintext highlighter-rouge">vector_add_thread.cu</code></li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$&gt;</span> <span class="nb">cp </span>vector_add.cu vector_add_thread.cu
</code></pre></div></div>

<ol>
  <li>
    <p>Paralelizar <code class="language-plaintext highlighter-rouge">vector_add()</code> usando un thread block con 256 threads.</p>
  </li>
  <li>
    <p>Compiler y evaluar perfomance del programa:</p>
  </li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$&gt;</span> nvcc vector_add_thread.cu <span class="nt">-o</span> vector_add_thread
<span class="nv">$&gt;</span> nvprof ./vector_add_thread
</code></pre></div></div>

<p>Ver solución en <a href="./CUDA/solutions/vector_add_thread.cu"><code class="language-plaintext highlighter-rouge">solutions/vector_add_thread.cu</code></a></p>

<p>Performance:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>==6430== Profiling application: ./vector_add_thread
==6430== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 39.18%  22.780ms         1  22.780ms  22.780ms  22.780ms  vector_add(float*, float*, float*, int)
 34.93%  20.310ms         2  10.155ms  10.137ms  10.173ms  [CUDA memcpy HtoD]
 25.89%  15.055ms         1  15.055ms  15.055ms  15.055ms  [CUDA memcpy DtoH]
</code></pre></div></div>

<p>Agregar mas <em>thread blocks</em></p>

<p>Las GPUs tienen muchos procesadores paralelos llamados <strong><em>Streaming Multiprocessors</em></strong> ó <strong><em>SMs</em></strong>. Cada SM consiste en multiples procesadores que puede correr thread blocks concurrentes en simultaneo.</p>

<p>De forma siilar a la información del thread, CUDA provee variables prefabricadas para acceder a la información del bloque.</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">blockIdx.x</code> contiene el indice del bloque en la grilla</li>
  <li><code class="language-plaintext highlighter-rouge">gridDim.x</code> contiene el tamaño de la grilla</li>
</ul>

<p>En lugar de usar un thread block para iterar sobre el array, vamos a usar multiple thread blocks para crear <code class="language-plaintext highlighter-rouge">N</code> threads, cada uno procesa un aelemento del array. <img src="./CUDA/02_parallel_block.png" alt="parallel block" title="parallel block" /></p>

<p>Con 256 threads por thread block, necesitaríamos por lo menos <code class="language-plaintext highlighter-rouge">N/256</code> thread block para tener un total de <code class="language-plaintext highlighter-rouge">N</code> threads. Para aignar un thread a un elemento especifico necesitamos saber el indice único de cada thread. Esto se computa así:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</code></pre></div></div>

<p><strong>EXERCISE: Try to implement this in <code class="language-plaintext highlighter-rouge">vector_add_grid.cu</code></strong></p>

<ol>
  <li>Copiar <code class="language-plaintext highlighter-rouge">vector_add.cu</code> a <code class="language-plaintext highlighter-rouge">vector_add_grid.cu</code></li>
</ol>

<p>$&gt; cp vector_add.cu vector_add_thread.cu</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
2. Parallelizar `vector_add()` usando multiple thread blocks. 

3. Manejar el caso cuando `N` es un numero arbitrario.
  * HINT: Add a condition to check that the thread work within the acceptable array index range. 

4. Compilar y evaluar performance

```bash
$&gt; nvcc vector_add_grid.cu -o vector_add_grid
$&gt; nvprof ./vector_add_grid
</code></pre></div></div>

<p>Ver solución en <a href="./solutions/vector_add_grid.cu"><code class="language-plaintext highlighter-rouge">solutions/vector_add_grid.cu</code></a></p>

<p>El  resultado de la performance fue en Tesla M2050</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>==6564== Profiling application: ./vector_add_grid
==6564== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 55.65%  20.312ms         2  10.156ms  10.150ms  10.162ms  [CUDA memcpy HtoD]
 41.24%  15.050ms         1  15.050ms  15.050ms  15.050ms  [CUDA memcpy DtoH]
  3.11%  1.1347ms         1  1.1347ms  1.1347ms  1.1347ms  vector_add(float*, float*, float*, int)
</code></pre></div></div>

<h2 id="comparación-de-performance">Comparación de performance</h2>

<table>
  <thead>
    <tr>
      <th>Version</th>
      <th style="text-align: right">Execution Time (ms)</th>
      <th style="text-align: right">Speedup</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1 thread</td>
      <td style="text-align: right">1425.29</td>
      <td style="text-align: right">1.00x</td>
    </tr>
    <tr>
      <td>1 block</td>
      <td style="text-align: right">22.78</td>
      <td style="text-align: right">62.56x</td>
    </tr>
    <tr>
      <td>Multiple blocks</td>
      <td style="text-align: right">1.13</td>
      <td style="text-align: right">1261.32x</td>
    </tr>
  </tbody>
</table>

<h2 id="acknowledgments">Acknowledgments</h2>

<ul>
  <li>Contents are adopted from <a href="https://devblogs.nvidia.com/even-easier-introduction-cuda/">An Even Easier Introduction to CUDA</a> by Mark Harris, NVIDIA and <a href="http://www.int.washington.edu/PROGRAMS/12-2c/week3/clark_01.pdf">CUDA C/C++ Basics</a> by Cyril Zeller, NVIDIA.</li>
</ul>

